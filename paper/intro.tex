Many commonly used C library functions return some value. In most cases, this value indicates something that is relevant to the  function's operations, such as a file descriptor, number of bytes processed, or a pointer to some data. Additionally, many functions that can fail return some predefined value indicating that an error occurred during the function's execution. Unfortunately, many programmers have the bad habit of not checking these return values for such error conditions, which can lead to undesirable behaviors, such as the program crashing or hanging. In our work, we used library interposition to intercept system/library calls in order to force an error value to randomly be returned to an application. In doing so, we were able to evaluate the robustness of these applications to returned error values.

Error handling takes many forms in the programs that were tested. For example, one of the simplest techniques (though not exactly considered the ``best practice'') is to simply \texttt{abort} on error, or \texttt{assert} that an error was not returned. We detected these situations based on the signal sent to kill the process. Although these are inelegant ways to terminate a program, nevertheless they are \emph{intentionally} performed by the programmer. Therefore, here we have used an expanded definition of robustness to mean that the program does not crash or hang. We define ``crash'' to mean an unintentional core dump (not brought about by the programmer) and ``hang'' to mean behavior that could only be ended by forcing the application to terminate (usually with \texttt{Ctrl-C}). This narrower definition of misbehavior allowed us to quantify program behavior in an unambiguous way.

Nearly all of the applications we tested displayed aberrant output that is likely not the behavior the developers intended, but this sort of behavior was too subjective for us to meaningfully measure. Nevertheless, we do include some of the more interesting aberrant behaviors that we found while testing.

In order to assess as large a representative sample of available programs as possible, we decided to focus on two major subgroups: small-scale (primarily command-line based) utilities, and large-scale (primarily GUI-based) programs. We restricted our sample to open-source projects, so as to be able to debug with source code available. Within small-scale utilities, we selected three groups to focus on: GNU Core Utilities (e.g. \texttt{ls}), the \texttt{net-tools} project (e.g. \texttt{ifconfig}), and selected other common utilities, such as \texttt{make} and \texttt{grep}. Within large-scale programs, we selected a sample of some of the largest and most common desktop programs available, such as Google Chrome, Mozilla Thunderbird, and \texttt{gcc}.
