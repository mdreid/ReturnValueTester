Our work is an extension of previous work in fuzz testing. Fuzz testing is conducted by passing randomly generated input to applications in order to find bugs. It was first developed by Miller et al. [?] in 1991. They used it to test how reliable UNIX applications were by counting the number that crashed or hung when passed fuzzed input. Surprisingly, they found that 25-33\% of the applications in the UNIX versions tested crashed or hung. In the same spirit, Miller et al. \cite{bart} fuzz tested more applications in 1995. They found that, although the programs that were tested in the previous study improved in reliability, many programs still crashed or hung. This study also applied fuzzing to test for failure to properly handle error return codes. To test the \texttt{malloc} family of calls, the authors intercepted \texttt{calloc}, \texttt{malloc}, and \texttt{realloc} calls from Unix applications, and with some probability $p$, returned an error value. With probability $1-p$, their program returned the true return code. Of the 53 applications tested, 25 crashed.  We extend this work by increasing both the number of calls and the number of applications tested.  

%As described by the Free Software Foundation, “the GNU core utilities are the basic file, shell and text manipulation utilities of the GNU operating system.” [?]. We selected a representative set of utilities listed in [?]. Net-tools is a set of UNIX applications for viewing and configuring network settings [?]. They have in large part been made obsolete by the “ip” utility. We tested both the Net-tools suite and the “ip” application for unchecked return values. Finally, we decided to test large projects to investigate their reliability. 