We found that the general intuition that large-scale applications are more difficult to get correct generally holds. Large-scale applications accounted for 11.4\% of the applications we tested, but made up 29.0\% of the applications that crashed. Furthmore, all of the hangs that we encountered occured when testing the large-scale applications, and they tended to crash with more calls than the small-scale utilities tested. These applications gained some robustness by using the GLib libraries, but ultimately the larger code base and greater complexity resulted in more places to miss error checking.

The memory allocation functions (\texttt{malloc}, \texttt{calloc}, and \texttt{realloc}) were the most common cause of core dumps, especially for small-scale utilities. This isn't surprising, given that an unchecked return value can lead to derefencing a null pointer and therefore a core dump. These results show that memory allocation has a major effect on robustness, and must be handled with care. Despite this, memory capacity continues to grow, and memory pressure is decreasingly thought of as a real possibility by programmers. These results suggest that programmers continue to make the same mistakes that have been described previously, however abundant memory may make these bugs less likely to arise in many situations.

A secondary goal of our work was to re-examine the results that Miller et al. encountered when fuzzing the return value of malloc family of functions. We included as many utilities previously tested as were availible in our own testing suite. In particular, we tested \texttt{ctags}, \texttt{df}, \texttt{finger}, \texttt{last}, \texttt{man}, \texttt{sdiff}, \texttt{tsort}, \texttt{users}, and \texttt{w}. All of these utilities resulted in crashes for Miller et al. under \texttt{malloc}, but we saw crashes in only \texttt{df}, \texttt{finger}, and \texttt{w}. This suggests that a number of utilities have become more robust since 1995.  
