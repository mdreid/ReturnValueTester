We found that the general intuition that large-scale applications are more difficult to get correct generally holds. Large-scale applications accounted for 11.4\% of the applications we tested, but made up 29.0\% of the applications that crashed or hung. Furthermore, all of the hangs that we encountered occurred when testing the large-scale applications, and they tended to crash or hang with more calls than the small-scale utilities tested. These applications gained some robustness by using the GLib libraries, but ultimately the larger codebase and greater complexity resulted in more places to miss error checking.

The memory allocation functions (\texttt{malloc}, \texttt{calloc}, and \texttt{realloc}) were the most common cause of core dumps, especially for small-scale utilities. This is not surprising, given that an unchecked return value can lead to derefencing a null pointer and therefore a core dump. These results show that memory allocation has a major effect on robustness, and must be handled with care. Despite this, memory capacity continues to grow, and memory pressure is decreasingly thought of as a real possibility by programmers. These results suggest that programmers continue to make the same mistakes that have been described previously, however abundant memory may make these bugs less likely to arise in many situations.

A secondary goal of our work was to re-examine the results that Miller et al. encountered when fuzzing the return value of \texttt{malloc} family of functions. We included as many utilities previously tested as were available in our own testing suite. In particular, we tested \texttt{ctags}, \texttt{df}, \texttt{finger}, \texttt{last}, \texttt{man}, \texttt{sdiff}, \texttt{tsort}, \texttt{users}, and \texttt{w}. All of these utilities resulted in crashes for Miller et al. under \texttt{malloc}, but we saw crashes in only \texttt{df}, \texttt{finger}, and \texttt{w}. This suggests that many utilities have become more robust since 1995.  

It is difficult to determine if a program is hanging or making progress on a computation. Therefore, one shortcoming in our approach is hang detection. A more systematic approach would take into account the distribution of runtimes of a given workload for a particular application, in order to determine with confidence that the application is hanging. This may remove ambiguity in the detection of hangs.

In our analysis of robustness, we have reported the percent of programs tested that crash or hang for at least one wrapped call. Another value that may be interesting is the percent of programs that invoke a particular wrapped call at least once, that crash or hang. This value may give a more fine-grained sense of how programs deal with error values from a particular call, rather than program reliability at large.